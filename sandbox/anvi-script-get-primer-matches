#!/usr/bin/env python
# -*- coding: utf-8

import os
import re
import sys
import copy

import anvio
import anvio.utils as utils
import anvio.terminal as terminal
import anvio.filesnpaths as filesnpaths

import IlluminaUtils.lib.fastqlib as u

from anvio.errors import ConfigError, FilesNPathsError

__author__ = "Developers of anvi'o (see AUTHORS.txt)"
__copyright__ = "Copyleft 2015-2019, the Meren Lab (http://merenlab.org/)"
__credits__ = []
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__authors__ = ['meren']
__provides__ = ["short-reads-fasta"]
__requires__ = ["samples-txt", "primers-txt"]
__description__ = ("You provide this program with FASTQ files for one or more samples AND one or more primer sequences, "
                   "and it collects reads from FASTQ files that matches to your primers. This tool can be "
                   "most powerful if you want to collect all short reads from one or more metagenomes that are "
                   "downstream to a known sequence. Using the comprehensive output files you can analyze the "
                   "diversity of seuqences visually, manually, or using established strategies such as oligotyping.")


pp = terminal.pretty_print
P = terminal.pluralize


class PrimerSearch:
    def __init__(self, args, run=terminal.Run(), progress=terminal.Progress()):
        self.args = args
        self.run = run
        self.progress = progress

        A = lambda x: args.__dict__[x] if x in args.__dict__ else None
        self.samples_txt = A('samples_txt')
        self.primers_file_path = A('primers_txt')
        self.output_directory_path = A('output_dir')
        self.min_remainder_length = A('min_remainder_length') or 60
        self.stop_after = A('stop_after')
        self.only_report_primer_matches = A('only_report_primer_matches')
        self.only_report_remainders = A('only_report_remainders')

        if self.only_report_primer_matches and self.only_report_remainders:
            raise ConfigError("You can't ask anvi'o to report only primer matches AND only remainders "
                              "at the same time. Please take a look at the help menu.")

        if self.only_report_primer_matches:
            self.min_remainder_length = 0

        filesnpaths.check_output_directory(self.output_directory_path)

        if not (A('samples_dict') or A('samples_txt')):
            raise ConfigError("This class is being initialized incorrectly :/ The `args` object must either include "
                              "path for a `samples-txt` file through `samples_txt` parameter, or a dictionary for "
                              "a samples dictionary through `samples_dict` parameter. See online help for more.")

        if not (A('primers_txt') or A('primers_dict')):
            raise ConfigError("This class is being initialized incorrectly :/ The `args` object must either include "
                              "path for a `primers-txt` file through `primers_txt` parameter, or a dictionary for "
                              "a primers dictionary through `primers_dict` parameter. See online help for more.")

        if self.samples_txt:
            self.samples_dict = utils.get_samples_txt_file_as_dict(self.samples_txt, run=run)
        else:
            self.samples_dict = A('samples_dict')
            if not isinstance(self.samples_dict, dict):
                raise ConfigError("The `primers_dict` parameter must be a literal dictionary.")

        if self.primers_file_path:
            self.primers_dict = utils.get_primers_txt_file_as_dict(self.primers_file_path)
        else:
            self.primers_dict = A('primers_dict')
            if not isinstance(self.primers_dict, dict):
                raise ConfigError("The `primers_dict` parameter must be a literal dictionary.")

        self.reads_are_processed = False

        # dictionary to keep track of some global counts for summary purposes
        self.stats = {'total_read_counter': 0,
                      'total_hits': 0,
                      'sample_counter': 0,
                      'samples': {}}

        # fill in default values
        for sample_name in self.samples_dict:
            self.stats['samples'][sample_name] = {'reads': 0,
                                                  'hits': 0,
                                                  'hits_in_rc': 0,
                                                  'primers': {}}

            for primer in self.primers_dict:
                self.stats['samples'][sample_name]['primers'][primer] = {'raw_hits': 0,
                                                                         'final_hits': 0,
                                                                         'shortest_seq_length_after_match': 0,
                                                                         'longest_remainder_length': 0,
                                                                         'avg_remainder_length': 0}

        self.sanity_check()
        self.print_class_setup()


    def sanity_check(self):
        if not self.samples_dict:
            raise ConfigError("The `self.samples_dict` object is empty :/ This class is initialized incorrectly. You either must ")


    def print_class_setup(self):
        """Display what's up"""

        self.run.info("Samples found", f"({len(self.samples_dict)}) {' '.join(self.samples_dict.keys())}")
        self.run.info("Primers found", f"({len(self.primers_dict)}) {'; '.join(self.primers_dict.keys())}")
        self.run.info('Output directory set', self.output_directory_path, nl_after=1)
        self.run.info('Min remainder length', self.min_remainder_length)
        if self.stop_after:
            self.run.info('Only report primer matches', self.only_report_primer_matches)
            self.run.info('Only report remainders', self.only_report_remainders)
            self.run.info('Stop after', self.stop_after, mc='red', nl_after=1)
        else:
            self.run.info('Only report remainders', self.only_report_remainders)
            self.run.info('Only report primer matches', self.only_report_primer_matches, nl_after=1)


    def process_sample(self, sample_name):
        sample_dict = copy.deepcopy(self.samples_dict[sample_name])
        sample_dict['hits'] = {}

        sample_stats = self.stats['samples'][sample_name]

        primers_dict = copy.deepcopy(self.primers_dict)

        for primer_name in primers_dict:
            primers_dict[primer_name]['matching_sequences'] = {}
            primers_dict[primer_name]['primer_length'] = len(primers_dict[primer_name]['primer_sequence'])

            sample_dict['hits'][primer_name] = 0
            primers_dict[primer_name]['matching_sequences'] = []


        # go through
        removed_due_to_remainder_length = 0
        for pair in ['r1', 'r2']:
            input_fastq_file_path = sample_dict[pair]
            input_fastq = u.FastQSource(input_fastq_file_path, compressed=input_fastq_file_path.endswith('.gz'))

            while input_fastq.next(raw=True) and (sample_stats['hits'] < self.stop_after if self.stop_after else True):
                sample_stats['reads'] += 1

                if sample_stats['reads'] % 10000 == 0:
                    self.progress.update(f"{sample_name} ({self.stats['sample_counter']} of {len(self.samples_dict)}) / {pair} / Reads: {pp(sample_stats['reads'])} / Hits: {pp(sample_stats['hits'])} (in RC: {pp(sample_stats['hits_in_rc'])})")

                found_in_RC = False

                for primer_name in primers_dict:
                    v = primers_dict[primer_name]
                    seq = input_fastq.entry.sequence
                    primer_sequence = v['primer_sequence']
                    match = re.search(primer_sequence, seq)

                    if not match:
                        # no match here. but how about the the reverse complement of it?
                        seq = utils.rev_comp(seq)

                        match = re.search(primer_sequence, seq)

                        if match:
                            # aha. the reverse complement sequence that carries our match found.
                            # will continue as if nothing happened
                            sample_stats['hits_in_rc'] += 1
                            found_in_RC = True

                    if not match:
                        continue

                    sample_stats['primers'][primer_name]['raw_hits'] += 1

                    if len(seq) - match.end() < self.min_remainder_length:
                        removed_due_to_remainder_length += 1
                        continue

                    v['matching_sequences'].append((match.start(), match.end(), seq), )

                    sample_stats['hits'] += 1
                    sample_stats['primers'][primer_name]['final_hits'] += 1

                    if anvio.DEBUG:
                        self.progress.end()
                        print("\n%s -- %s -- %s| %s [%s] %s" % (sample_name, pair, 'RC ' if found_in_RC else '   ', seq[:match.start()], primer_sequence, seq[match.end():]))
                        self.progress.new("Tick tock")
                        self.progress.update(f"{sample_name} ({self.stats['sample_counter']} of {len(self.samples_dict)}) / {pair} / Reads: {pp(sample_stats['reads'])} / Hits: {pp(sample_stats['hits'])} (in RC: {pp(sample_stats['hits_in_rc'])})")

            self.stats['total_read_counter'] += sample_stats['reads']
            self.stats['total_hits'] += sample_stats['hits']

            # calculate and store stats for primer hits
            for primer_name in primers_dict:
                matching_sequence_hits = primers_dict[primer_name]['matching_sequences']
                seq_lengths_after_match = [len(sequence[end:]) for start, end, sequence in matching_sequence_hits]

                if len(seq_lengths_after_match):
                    sample_stats['primers'][primer_name]['shortest_seq_length_after_match'] = min(seq_lengths_after_match)
                    sample_stats['primers'][primer_name]['longest_remainder_length'] = max(seq_lengths_after_match)
                    sample_stats['primers'][primer_name]['avg_remainder_length'] = sum(seq_lengths_after_match) / len(seq_lengths_after_match)

        return sample_dict, primers_dict


    def process(self):
        """Processes everything."""


        for sample_name in self.samples_dict:
            self.progress.new("Tick tock")
            self.progress.update('...')
            self.stats['sample_counter'] += 1
            sample_dict, primers_dict = self.process_sample(sample_name)
            self.progress.end()

            if self.output_directory_path:
                self.store_sequences(sample_name, sample_dict, primers_dict)

            # call Batman
            del sample_dict
            del primers_dict

        self.reads_are_processed = True


    def print_summary(self):
        """Prints a fancy summary of the results"""

        if not self.reads_are_processed:
            raise ConfigError("You first need to call the member function `process`.")

        self.run.warning(None, header="FINAL SUMMARY", lc='yellow')
        self.run.info_single(f"After processing {pp(self.stats['total_read_counter'])} individual reads in {P('sample', len(self.samples_dict))}, "
                             f"anvi'o found {P('hit', self.stats['total_hits'])} for your {P('sequence', len(self.primers_dict), pfs='only')} "
                             f"in the primer sequences file. What is shown below breaks these numbers down per sample because that's how "
                             f"anvi'o rolls. There are some acronyms below, and they are very creatively named. RH: number of raw hits (the actual "
                             f"number of times a primer matched to a sequence). FH: number of final hits (after testing whether the remainder length "
                             f"was longer than the user-set or default minimum value). SRL: shortest remainder length. LRL: Longest remainder length. "
                             f"ARL: Average remainder length after match).", level=0)

        for sample_name in self.samples_dict:
            self.run.info(f"{sample_name}", f"{pp(self.stats['samples'][sample_name]['reads'])} total reads", nl_before=1, lc="green", mc="green")
            for primer_sequence in self.primers_dict:
                s = self.stats['samples'][sample_name]['primers'][primer_sequence]
                self.run.info(f"    {primer_sequence}", f"RH: {pp(s['raw_hits']) if s['raw_hits'] else '--'} / "
                                                        f"FH: {pp(s['final_hits']) if s['final_hits'] else '--'} / "
                                                        f"SRL: {s['shortest_seq_length_after_match'] if s['shortest_seq_length_after_match'] else '--'} / "
                                                        f"LRL: {s['longest_remainder_length'] if s['longest_remainder_length'] else '--'} / "
                                                        f"ARL: {s['avg_remainder_length']:.2f}", mc=('yellow' if s['final_hits'] else 'red'))

        if not self.stats['total_read_counter']:
            self.run.info_single('No hits were found :/', mc='red', nl_before=1)


    def store_sequences(self, sample_name, sample_dict, primers_dict):
        """Store sequence files for a given sample under `self.output_directory_path`"""

        if not self.output_directory_path:
            return

        if not os.path.exists(self.output_directory_path):
            filesnpaths.gen_output_directory(self.output_directory_path)

        self.run.info_single(f"Output files for {sample_name}:", nl_before=1, mc="green")

        if self.only_report_remainders:
            self.progress.new("Generating the remainders file")
            self.progress.update('...')
            for primer_sequence in primers_dict:
                matching_sequence_hits = primers_dict[primer_sequence]['matching_sequences']

                output_file_path = os.path.join(self.output_directory_path, '%s-%s-REMAINDERS.fa' % (sample_name, primer_sequence))
                with open(output_file_path, 'w') as output:
                    counter = 1
                    for start, end, sequence in matching_sequence_hits:
                        if self.min_remainder_length:
                            output.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence[end:end + self.min_remainder_length]}\n')
                        else:
                            output.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence[end:]}\n')
                        counter += 1
            self.progress.end()

            self.run.info(f'    Remainders sequences', os.path.join(self.output_directory_path, f'{sample_name}-*-REMAINDERS.fa'))

            return

        self.progress.new("Generating the raw hits files")
        self.progress.update('...')
        for primer_sequence in primers_dict:
            matching_sequence_hits = primers_dict[primer_sequence]['matching_sequences']

            output_file_path = os.path.join(self.output_directory_path, '%s-%s-HITS.fa' % (sample_name, primer_sequence))
            with open(output_file_path, 'w') as output:
                counter = 1
                for start, end, sequence in matching_sequence_hits:
                    output.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence[start:end]}\n')
                    counter += 1
        self.progress.end()

        self.run.info(f'    Raw hits', os.path.join(self.output_directory_path, f'{sample_name}-*-HITS.fa'))

        if self.only_report_primer_matches:
            return

        self.progress.new("Generating the fancy hits files")
        self.progress.update('...')
        for primer_sequence in self.primers_dict:
            trimmed_output_file_path = os.path.join(self.output_directory_path, '%s-%s-HITS-TRIMMED.fa' % (sample_name, primer_sequence))
            gapped_output_file_path = os.path.join(self.output_directory_path, '%s-%s-HITS-WITH-GAPS.fa' % (sample_name, primer_sequence))

            matching_sequence_hits = primers_dict[primer_sequence]['matching_sequences']
            primer_length = primers_dict[primer_sequence]['primer_length']
            seq_lengths_after_match = [len(sequence[end:]) for start, end, sequence in matching_sequence_hits]

            with open(trimmed_output_file_path, 'w') as trimmed, open(gapped_output_file_path, 'w') as gapped:
                max_seq_length = (max(seq_lengths_after_match) + primer_length) if len(seq_lengths_after_match) else 0
                min_seq_length = (min(seq_lengths_after_match) + primer_length) if len(seq_lengths_after_match) else 0
                counter = 1
                for start, end, sequence in matching_sequence_hits:
                    sequence = sequence[start:]

                    sequence = sequence + '-' * (max_seq_length - len(sequence))
                    gapped.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence}\n')

                    sequence = sequence[:min_seq_length]
                    trimmed.write(f'>{sample_name}_{primer_sequence}_{counter:05d}\n{sequence}\n')

                    counter += 1
        self.progress.end()

        self.run.info(f'    Trimmed hits', os.path.join(self.output_directory_path, f'{sample_name}-*-HITS.fa'))
        self.run.info(f'    Hits with gaps', os.path.join(self.output_directory_path, f'{sample_name}-*-HITS.fa'))

        return


if __name__ == '__main__':
    from anvio.argparse import ArgumentParser
    parser = ArgumentParser(description=__description__)

    groupA = parser.add_argument_group('INPUT FILES', "Here you are expected to declare your FASTQ files and sequences "
                            "which you are interested to find in those FASTQ files. Each file should have at least one "
                            "entry")
    groupA.add_argument(*anvio.A('samples-txt'), **anvio.K('samples-txt'))
    groupA.add_argument('--primers-txt', required=True, metavar='FILE', help="A two-column file that contains one "
                            "or more primer sequences. See the primers-txt artifact for details.")

    groupB = parser.add_argument_group('PARAMETERS OF LIFE OR DEATH', "Here you are expected to set appropriate "
                            "parameters for your search (or you can choose to go with the defaults)")
    groupB.add_argument('-m', '--min-remainder-length', metavar='INT', type=int, default=60,
                        help="Minimum length of the remainder of the read after a match. If your short read "
                              "is XXXMMMMMMYYYYYYYYYYYYYY, where Ms indicate the primer sequence, "
                              "min remainder length is equal to the length of nucleotide matching Y. Default is %(default)d.")
    groupB.add_argument('-x', '--only-report-primer-matches', default=False, action="store_true",
                        help="For a given sequence with a primer match, report only the part of it that matches to the primer. "
                             "In other words, if your short read is XXXMMMMMMYYYYYYYYYYYYYY, where Ms indicate part of your "
                             "sequence that matches to the primer, setting this flag will remove all Xs and Ys. Setting "
                             "this flag will automatically set the `--min-remainder-length` to 0. If you have a problem with "
                             "that, let us know.")
    groupB.add_argument('-R', '--only-report-remainders', default=False, action="store_true",
                        help="For a given sequence with a primer match, report only the part that follows the primer. "
                             "In other words, if your short read is XXXMMMMMMYYYYYYYYYYYYYY, where Ms indicate part of your "
                             "sequence that matches to the primer, setting this flag will only report Ys. This flag "
                             "is obviously incompatible with `--only-report-primer-matches` flag.")

    groupC = parser.add_argument_group('TESTING?', "Be our guest.")
    groupC.add_argument('--stop-after', metavar='INT', type=int, default=0, help="Stop after X number of hits because "
                               "who needs data.")

    groupD = parser.add_argument_group('OUTPUT', "Tell anvi'o where to put your thingies")
    groupD.add_argument(*anvio.A('output-dir'), **anvio.K('output-dir', {'required': True}))

    args = parser.get_args(parser)

    try:
        s = PrimerSearch(args)
        s.process()
        s.print_summary()
    except ConfigError as e:
        print(e)
        sys.exit(-1)
    except FilesNPathsError as e:
        print(e)
        sys.exit(-2)
