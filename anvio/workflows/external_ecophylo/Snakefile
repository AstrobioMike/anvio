# -*- coding: utf-8
import os
import glob
import json
import os.path
import argparse

import numpy as np
import pandas as pd

import anvio
import anvio.utils as u
import anvio.workflows as w

from Bio import SeqIO
from anvio.errors import ConfigError
from anvio.workflows.external_ecophylo import ExternalEcoPhyloWorkflow

__author__ = "Matthew S. Schechter"
__copyright__ = "Copyright 2017, The anvio Project"
__credits__ = []
__license__ = "GPL 3.0"
__version__ = anvio.__version__
__maintainer__ = "Matthew S. Schechter"
__email__ = "mschechter@uchicago.edu"


M = ExternalEcoPhyloWorkflow(argparse.Namespace(config=config))
M.init()

dirs_dict = M.dirs_dict

rule ECO_PHYLO_WORKFLOW_target_rule:
    input: M.target_files

rule anvi_run_hmms_hmmsearch:
    """Run hmmsearch with input HMMs to get domtblout"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_run_hmms_hmmsearch_{sample_name}_{external_hmm}.log")
    input:
    output:
        done = touch(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}_{external_hmm}_dom_hmmsearch/contigs-hmmsearch.done")),
        domtable = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}_{external_hmm}_dom_hmmsearch/hmm.domtable"),
        hmm_table = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}_{external_hmm}_dom_hmmsearch/hmm.table")
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
      contigsDB = os.path.join(M.input_dirs_dict[wildcards.sample_name], "{wildcards.sample_name}-contigs.db")
      external_hmm_dir = os.path.join(M.external_HMM_dict[wildcards.external_hmm])
      hmmer_output_dir = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], f"{wildcards.sample_name}_{wildcards.external_hmm}_dom_hmmsearch")

      shell(f"anvi-run-hmms -c {contigsDB} \
                           --hmmer-program hmmsearch \
                           --hmm-profile-dir {external_hmm_dir} \
                           --hmmer-output-dir {hmmer_output_dir} \
                           --domain-hits-table \
                           --just-do-it \
                           -T {threads} 2> {log}")


rule filter_hmm_hits_by_query_coverage:
    """Filter hmm_hits table by query coverage using domtblout"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "filter_hmm_hits_by_query_coverage_{sample_name}.log")
    input:
        done = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}-contigs-hmmsearch.done"),
        domtblout = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}_dom_hmmsearch/hmm.domtable"),
    output:
        touch(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}_contigsDB_filtered.done"))
    params:
        hmm_source = M.get_param_value_from_config(['filter_hmm_hits_by_query_coverage', '--hmm-source']),
        query_coverage = M.get_param_value_from_config(['filter_hmm_hits_by_query_coverage', '--query-coverage']),
        additional_params = M.get_param_value_from_config(['filter_hmm_hits_by_query_coverage', 'additional_params'])
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
      contigsDB = os.path.join(M.input_dirs_dict[wildcards.sample_name], "%s-contigs.db" % wildcards.sample_name)
      domtblout = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "%s_dom_hmmsearch/hmm.domtable" % wildcards.sample_name)

      shell("anvi-script-filter-hmm-hits-table -c %s \
                                               --domain-hits-table %s \
                                               --hmm-source {params.hmm_source} \
                                               --query-coverage {params.query_coverage} \
                                               {params.additional_params} 2> {log}" % (contigsDB, domtblout))

rule anvi_get_sequences_for_hmm_hits_SCGs_aa:
    """Extract all SCG AA sequences listed in SCG_protein_list.txt from metagenomes.txt and external_genomes.txt"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_get_sequences_for_hmm_hits_SCGs_AA_{sample_name}_{external_hmm}.log")
    input:
        done_file = rules.anvi_run_hmms_hmmsearch.output.done,
        contigsDB = ancient(lambda wildcards: os.path.join(M.input_dirs_dict[wildcards.sample_name], "%s-contigs.db" % wildcards.sample_name))
    output:
        done = touch(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits.faa.done")),
        faa = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits.faa")
    params:
        hmm_source = M.get_rule_param('anvi_get_sequences_for_hmm_hits_SCGs', '--hmm-source')
    threads: M.T('anvi_get_sequences_for_hmm_hits_SCGs')
    run:
        external_hmm_name = os.path.basename(M.external_HMM_dict[wildcards.external_hmm])
        # print(M.external_HMM_dict)
        # print(M.external_HMM_dict[wildcards.external_hmm])
        # print(os.path.basename(str(M.external_HMM_dict[wildcards.external_hmm])))
        # print("working? " + os.path.basename("~/Downloads/Adenylsucc_synt/"))
        shell(f"anvi-get-sequences-for-hmm-hits -c {input.contigsDB} \
                                               --hmm-sources  {external_hmm_name} \
                                               --get-aa-sequences \
                                               -o {output.faa} 2> {log}")

rule anvi_get_sequences_for_hmm_hits_SCGs_nt:
    """Extract all SCG NT sequences listed in SCG_protein_list.txt from metagenomes.txt and external_genomes.txt"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_get_sequences_for_hmm_hits_SCGs_NT_{sample_name}_{external_hmm}.log")
    input:
        done_file = rules.anvi_get_sequences_for_hmm_hits_SCGs_aa.output.done,
        contigsDB = ancient(lambda wildcards: os.path.join(M.input_dirs_dict[wildcards.sample_name], "%s-contigs.db" % wildcards.sample_name))
    output:
        fna = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits.fna"),
        done = touch(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits.fna.done"))
    params:
        hmm_source = M.get_rule_param('anvi_get_sequences_for_hmm_hits_SCGs', '--hmm-source')
    threads: M.T('anvi_get_sequences_for_hmm_hits_SCGs')
    run:
        external_hmm_name = os.path.basename(M.external_HMM_dict[wildcards.external_hmm])
        shell(f"anvi-get-sequences-for-hmm-hits -c {input.contigsDB} \
                                               --hmm-sources  {external_hmm_name} \
                                               -o {output.fna} 2> {log}")


rule get_external_gene_calls_file:
    """Extract external_gene_calls table fromsamples"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "get_external_gene_calls_file_{sample_name}_{external_hmm}.log")
    input:
        done = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits.fna.done"),
        contigsDB = ancient(lambda wildcards: os.path.join(M.input_dirs_dict[wildcards.sample_name], "%s-contigs.db" % wildcards.sample_name))
    output:
        # external_gene_calls_ed = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_external_gene_calls_ed.tsv"),
        external_gene_calls = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_external_gene_calls.tsv")
    params:
        fasta = temp(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_orfs.fna")),
        # external_gene_calls = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_external_gene_calls.tsv")
    threads: M.T('anvi_get_sequences_for_hmm_hits_SCGs')
    shell:
          """
          anvi-get-sequences-for-gene-calls -c {input.contigsDB} \
                                            --external-gene-calls {output.external_gene_calls} \
                                            -o {params.fasta} 2> {log}
          """

rule cat_external_gene_calls_file:
    """Cat all external_gene_calls files from all samples into one file"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "cat_ribo_proteins_to_one_fasta_{external_hmm}.log")
    input:
        external_gene_calls_renamed = expand(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_names}", "{sample_names}_{{external_hmm}}_external_gene_calls.tsv"), sample_names = M.names_list, external_hmms = M.external_HMM_dict.keys()),
    output:
        external_gene_calls_all = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_external_gene_calls_all.tsv"),
    threads: M.T('cat_ribo_proteins_to_one_fasta')
    shell:
        "cat {input.external_gene_calls_renamed} >> {output.external_gene_calls_all} 2> {log}"

rule rename_and_filter_external_gene_calls_file_all:
    """"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "rename_and_filter_external_gene_calls_file_all_{external_hmm}.log")
    input:
        external_gene_calls_all = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_external_gene_calls_all.tsv"),
        # SCGs_nt = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_scgs_for_mapping.fna"),
        reformat_file_all = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_reformat_report_all.txt"),
        # headers = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}", "{external_hmm}_headers_for_mapping.txt")
    output:
        external_gene_calls_renamed = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_external_gene_calls_all_renamed.tsv"),
        done = touch(os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_external_gene_calls_all_renamed.done"))
    threads: 5
    script:
        "scripts/rename_external_gene_calls_file.py"

rule simplify_names_from_scg_hits_nt:
    """Clean up fasta headers for tree calculation"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_reformat_fasta_ribosomal_protein_file_{sample_name}_{external_hmm}.log")
    input: os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits.fna")
    output:
        fasta = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits_renamed.fna"),
        report_file = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_reformat_report_nt.txt")
    threads: M.T('anvi_script_reformat_fasta')
    shell:
        "anvi-script-reformat-fasta {input} \
                              --simplify-names \
                              --prefix {wildcards.sample_name} \
                              --report-file {output.report_file} \
                              -o {output.fasta} >> {log} 2>&1"

rule change_names_scg_hits_nt:
    """"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_reformat_fasta_ribosomal_protein_file_{sample_name}_{external_hmm}.log")
    input:
        fasta = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits_renamed.fna"),
        report_file = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_reformat_report_nt.txt"),
    output:
        fasta_renamed = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits_renamed_final.fna"),
    threads: M.T('anvi_script_reformat_fasta')
    run:
        import pandas as pd
        import numpy as np
        import glob
        import os.path

        from Bio import SeqIO
        from snakemake.shell import shell

        # Import import fasta as dataframe
        fasta_df = pd.DataFrame({'header': [], 'sequence': []})

        for seq_record in SeqIO.parse(str(input.fasta), "fasta"):
            fasta_df = fasta_df.append({'new_header': str(seq_record.description), 'sequence': str(seq_record.seq)}, ignore_index=True)

        reformat_report = pd.read_csv(input.report_file, \
                  sep="\t", \
                  index_col=None,
                  names=['new_header', 'old_header'])


        reformat_report['gene_callers_id'] = reformat_report['old_header'].str.split("gene_callers_id:|\|start:", expand=True)[1].astype(int)
        reformat_report['sequence_name'] = wildcards.sample_name + '_' + wildcards.external_hmm + '_' + reformat_report['gene_callers_id'].map(str)

        merged = pd.merge(reformat_report, fasta_df, on='new_header')

        seq_dict = dict(zip(merged.sequence_name, merged.sequence))

        #File output
        fileOutput = open(output.fasta_renamed, "w")

        #Loop through each line in the input file
        for key,value in seq_dict.items():

            #Output the header
            fileOutput.write(">" + str(key) + "\n")
            fileOutput.write(value + "\n")

        #Close the input and output file
        fileOutput.close()


rule change_names_scg_hits_aa:
    """"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_reformat_fasta_ribosomal_protein_file_{sample_name}_{external_hmm}.log")
    input:
        fasta = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits_renamed.faa"),
        report_file = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_reformat_report_aa.txt"),
    output:
        fasta_renamed = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits_renamed_final.faa"),
    threads: M.T('anvi_script_reformat_fasta')
    run:
        import pandas as pd
        import numpy as np
        import glob
        import os.path

        from Bio import SeqIO
        from snakemake.shell import shell

        # Import import fasta as dataframe
        fasta_df = pd.DataFrame({'header': [], 'sequence': []})

        for seq_record in SeqIO.parse(str(input.fasta), "fasta"):
            fasta_df = fasta_df.append({'new_header': str(seq_record.description), 'sequence': str(seq_record.seq)}, ignore_index=True)

        reformat_report = pd.read_csv(input.report_file, \
                  sep="\t", \
                  index_col=None,
                  names=['new_header', 'old_header'])


        reformat_report['gene_callers_id'] = reformat_report['old_header'].str.split("gene_callers_id:|\|start:", expand=True)[1].astype(int)
        reformat_report['sequence_name'] = wildcards.sample_name + '_' + wildcards.external_hmm + '_' + reformat_report['gene_callers_id'].map(str)

        merged = pd.merge(reformat_report, fasta_df, on='new_header')

        seq_dict = dict(zip(merged.sequence_name, merged.sequence))

        #File output
        fileOutput = open(output.fasta_renamed, "w")

        #Loop through each line in the input file
        for key,value in seq_dict.items():

            #Output the header
            fileOutput.write(">" + str(key) + "\n")
            fileOutput.write(value + "\n")

        #Close the input and output file
        fileOutput.close()


rule simplify_names_from_scg_hits_aa:
    """Clean up fasta headers for tree calculation"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_reformat_fasta_ribosomal_protein_file_{sample_name}_{external_hmm}.log")
    input: os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", '{sample_name}_{external_hmm}_hmm_hits.faa')
    output:
        fasta = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_hmm_hits_renamed.faa"),
        report_file = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_reformat_report_aa.txt")
    threads: M.T('anvi_script_reformat_fasta')
    shell:
        "anvi-script-reformat-fasta {input} \
                              --simplify-names \
                              --prefix {wildcards.sample_name} \
                              --report-file {output.report_file} \
                              -o {output.fasta} >> {log} 2>&1"

rule cat_scgs_to_one_fasta_nt:
    """
    Cat all SCG sequences from seperate metagenomes into one fasta
    FIXME: the "{external_hmm}/{external_hmm}_all.fasta" can be removed because only the renamed
    version of the fasta file is referenced for the rest of the workflow
    """

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "cat_ribo_proteins_to_one_fasta_{external_hmm}.log")
    input:
        fasta = expand(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_names}", "{sample_names}_{{external_hmm}}_hmm_hits_renamed_final.fna"), sample_names = M.names_list, external_hmms = M.external_HMM_dict.keys()),
    output:
        fasta_all = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_all.fna"),
    threads: M.T('cat_ribo_proteins_to_one_fasta')
    shell:
        "cat {input.fasta} >> {output.fasta_all}"

rule cat_reformat_files_nt:
    """
    Cat all SCG reformat files from seperate metagenomes into one fasta
    FIXME: the "{external_hmm}/{external_hmm}_all.fasta" can be removed because only the renamed
    version of the fasta file is referenced for the rest of the workflow
    """

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "cat_ribo_proteins_to_one_fasta_{external_hmm}.log")
    input:
        reformat_file = expand(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_names}", "{sample_names}_{{external_hmm}}_reformat_report_nt.txt"), sample_names = M.names_list, external_hmms = M.external_HMM_dict.keys()),
    output:
        reformat_file_all = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_reformat_report_all.txt")
    threads: M.T('cat_ribo_proteins_to_one_fasta')
    shell:
        "cat {input.reformat_file} >> {output.reformat_file_all}"

rule cat_scgs_to_one_fasta_aa:
    """
    Cat all SCG AA sequences from seperate metagenomes into one fasta
    FIXME: the "{external_hmm}/{external_hmm}_all.fasta" can be removed because only the renamed
    version of the fasta file is referenced for the rest of the workflow
    """

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "cat_ribo_proteins_to_one_fasta_{external_hmm}.log")
    input: expand(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_names}", "{sample_names}_{{external_hmm}}_hmm_hits_renamed_final.faa"), sample_names = M.names_list, external_hmms = M.external_HMM_dict.keys())
    output: fasta = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_all.faa")
    threads: M.T('cat_ribo_proteins_to_one_fasta')
    shell:
        "cat {input} >> {output.fasta}"


def get_misc_data_about_clusters(mmseqs_cluster_rep_index, final_sequences_headers, output):
    """Add contig_db_type to misc data"""

    # Import data
    #------------
    cluster_rep_index = pd.read_csv(mmseqs_cluster_rep_index, \
                                    sep="\t", \
                                    index_col=False, \
                                    names=["representative", "cluster_members"])

    final_sequences_headers = pd.read_csv(final_sequences_headers, \
                                    sep="\t", \
                                    index_col=False, \
                                    header=None)
    # If metagenome_name is in external_genomes_names_list then it's a genome
    #------------------------------------------------------------------------
    # print(cluster_rep_index.head())
    # print()
    # reformat_report['old_header'].str.split("gene_callers_id:|\|start:", expand=True)[1].astype(int)
    cluster_rep_index['sample_name'] = cluster_rep_index["representative"].str.split("_").str[:-2].str.join("_").astype(str)
    cluster_rep_index["contig_db_type"] = np.where(cluster_rep_index["sample_name"].isin(M.external_genomes_names_list), "genome", "metagenome")

    # Detect if there is a genomic reference protein in cluster
    #----------------------------------------------------------
    cluster_rep_index_dict = cluster_rep_index.groupby('representative')['cluster_members'].apply(list).to_dict()

    sup_list = []
    for seq in final_sequences_headers.iloc[:, 0].tolist():
        cluster_members_list = cluster_rep_index_dict[seq]
        for external_genome in M.external_genomes_names_list:
            check = any(external_genome in s for s in cluster_members_list)
            if check is True:
                sup_list.append(seq)


    cluster_rep_index['has_genomic_reference_protein_in_cluster'] = np.where(cluster_rep_index['representative'].isin(sup_list), 'yes', 'no')

    # Make split name column for mapping
    #-----------------------------------
    cluster_rep_index['split_name'] = cluster_rep_index['representative'].astype(str) + '_split_00001'
    first_column = cluster_rep_index.pop('split_name')
    cluster_rep_index.insert(0, 'split_name', first_column)

    # Count size of clusters
    #-----------------------
    df = cluster_rep_index.groupby('representative').apply(count_cluster_size)[['cluster_members', 'cluster_size']]

    misc_data = pd.merge(cluster_rep_index, df, on='cluster_members')

    misc_data = misc_data.rename(columns={'representative': 'identifier', 'oldName2': 'newName2'})

    misc_data = misc_data[['split_name', 'identifier', 'contig_db_type', 'has_genomic_reference_protein_in_cluster', 'cluster_size']].drop_duplicates()

    # Export
    #-------
    misc_data.to_csv(output, \
                    sep="\t", \
                    index=None, \
                    na_rep="NA")

def count_cluster_size(group):
    c = group['cluster_members'].count()
    group['cluster_size'] = c

    return group


rule add_misc_data_to_taxonomy:
    """Add simplified fasta headers to the misc data file"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "add_contigsDB_type_{external_hmm}.log")
    input:
        final_list_of_sequences_for_mapping_headers = os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_headers.tmp")
    output:
        misc_data_final = os.path.join(dirs_dict['MISC_DATA'], "{external_hmm}_misc.tsv")
    params:
        cluster_rep_index = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}", "{external_hmm}_mmseqs_NR_cluster.tsv")
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
        """Here we determine the origin of each SCG (which kind of contigsDB): metagenome, isolate genome, etc."""
        get_misc_data_about_clusters(mmseqs_cluster_rep_index = params.cluster_rep_index,
                                     final_sequences_headers = input.final_list_of_sequences_for_mapping_headers,
                                     output = output.misc_data_final)


rule anvi_get_external_gene_calls_file:
    """Extract external_gene_calls table from all samples"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "get_external_gene_calls_file_{sample_name}_{external_hmm}.log")
    input:
        done = rules.filter_hmm_hits_by_query_coverage.output,
        contigsDB = ancient(lambda wildcards: os.path.join(M.input_dirs_dict[wildcards.sample_name], "%s-contigs.db" % wildcards.sample_name))
    output:
        external_gene_calls = os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_external_gene_calls.tsv")
    params:
        fasta = temp(os.path.join(dirs_dict['EXTRACTED_RIBO_PROTEINS_DIR'], "{sample_name}", "{sample_name}_{external_hmm}_orfs.fna")),
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
        shell('anvi-get-sequences-for-gene-calls -c {input.contigsDB} \
                                                 --external-gene-calls {output.external_gene_calls} \
                                                 -o {params.fasta} 2> {log}')


rule subset_external_gene_calls_file_all:
    """"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "rename_and_filter_external_gene_calls_file_all_{external_hmm}.log")
    input:
        external_gene_calls_all = rules.rename_and_filter_external_gene_calls_file_all.output.external_gene_calls_renamed,
        headers = os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_headers.tmp")
    output:
        external_gene_calls_subset = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_external_gene_calls_subset.tsv"),
    threads: 5
    script:
        "scripts/subset_external_gene_calls_file.py"


rule cluster_X_percent_sim_mmseqs:
    """
    Cluster SCG NT sequences with mmseqs to remove redundant SCG sequences which will prevent non-specific read recruitment
    and read recruitment dilution.
    """

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "cluster_90_mmseqs_{external_hmm}.log")
    input: rules.cat_scgs_to_one_fasta_nt.output.fasta_all
    output: os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}", "{external_hmm}_mmseqs_NR_rep_seq.fasta")
    params:
        output_prefix = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}", "{external_hmm}_mmseqs_NR"),
        mmseqs_tmp = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}", "{external_hmm}_tmp"),
        min_seq_id = M.get_param_value_from_config(['remove_redundant_sequences_mmseqs', '--min-seq-id'])
    threads: M.T('remove_redundant_sequences_mmseqs')
    shell:
        "mmseqs easy-cluster {input} \
                             {params.output_prefix} \
                             {params.mmseqs_tmp} \
                             --threads {threads} \
                             --min-seq-id {params.min_seq_id} >> {log} 2>&1"


rule subset_AA_seqs_with_mmseqs_reps:
    """Subset AA sequences for the mmseqs cluster representatives"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_reformat_fasta_ribosomal_protein_file_{external_hmm}.log")
    input:
        fa = rules.cat_scgs_to_one_fasta_aa.output.fasta,
        reps = rules.cluster_X_percent_sim_mmseqs.output
    output:
        fasta = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_AA_subset.fa"),
        headers = temp(os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_headers.tmp"))
    threads: M.T('anvi_script_reformat_fasta')
    shell:
        """
        grep '>' {input.reps} | sed 's/>//g' > {output.headers}

        anvi-script-reformat-fasta {input.fa} -I {output.headers} -o {output.fasta} >> {log} 2>&1
        """


rule align_sequences:
    """MSA of AA sequences subset."""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "align_sequences_{external_hmm}.log")
	input: rules.subset_AA_seqs_with_mmseqs_reps.output.fasta
	output: os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_aligned.fa")
	threads: M.T('align_sequences')
	shell:
		"muscle -in {input} -out {output} -maxiters 2 -verbose 2> {log}"


rule trim_alignments:
    """Trim alignment"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "trim_alignments_{external_hmm}.log")
    input: rules.align_sequences.output
    output: os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_aligned_trimmed.fa")
    params:
        gt = M.get_param_value_from_config(['trim_alignments', '-gt']),
        gappyout = M.get_rule_param('trim_alignments', '-gappyout'),
        additional_params = M.get_param_value_from_config(['trim_alignments', 'additional_params'])
    shell:
        'trimal -in {input} \
                -out {output} \
                {params.gappyout} \
                {params.additional_params} 2> {log}'

rule remove_sequences_with_X_percent_gaps:
    """Removing sequences that have Z > X% gaps"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "remove_gaps_{external_hmm}.log")
    input: rules.trim_alignments.output
    output: os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_aligned_trimmed_filtered.fa")
    params:
        seq_counts_tsv = os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_gaps_counts"),
        max_percentage_gaps = M.get_param_value_from_config(['remove_sequences_with_X_percent_gaps', '--max-percentage-gaps'])
    threads: M.T('remove_gaps')
	shell:
		"anvi-script-reformat-fasta {input} \
									-o {output} \
									--max-percentage-gaps {params.max_percentage_gaps} \
									--export-gap-counts-table {params.seq_counts_tsv} >> {log} 2>&1"


rule count_num_sequences_filtered:
    """Record the number of sequences filtered at each step of the workflow"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "count_num_sequences_filtered_{external_hmm}.log")
    input:
        step1 = rules.cat_scgs_to_one_fasta_nt.output.fasta_all,
        step2 = rules.cluster_X_percent_sim_mmseqs.output,
        step3 = rules.remove_sequences_with_X_percent_gaps.output
    output: os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_MSA_STATS'], "{external_hmm}/{external_hmm}_stats.tsv")
    threads: M.T('trim_alignments_2')
    shell:
        """
        # How many SCGs (e.g. Ribosomal_L16) did we recruit across all input data (genomes and metagenomes)?
        step1=$(grep -c '>' {input.step1})
        echo -e "anvi_estimate_scg_taxonomy_for_SCGs.output.DNA_fasta\t$step1\t{input.step1}\n" > {output}

        # How many SCGs do we have after we cluster them at the nt level and pick representatives?
        step2=$(grep -c '>' {input.step2})
        echo -e "cluster_X_percent_sim_mmseqs\t$step2\t{input.step2}\n" >> {output}

        # How many seqs are in the NR set?
        step3=$(grep -c '>' {input.step3})
        echo -e "remove_sequences_with_X_percent_gaps\t$step3\t{input.step3}\n" >> {output}

        # Add column names here
        echo -e "Rule_name\tNum_sequences\trel_path\n$(cat {output})" > {output}
        """


rule subset_DNA_reps_with_QCd_AA_reps_for_mapping:
    """Filter for SCG NT sequences what will be used for read recruitment later"""

    version: 1.0
    input:
        fasta = rules.cat_scgs_to_one_fasta_nt.output.fasta_all,
        reps = rules.remove_sequences_with_X_percent_gaps.output
    output:
        NT_for_mapping = os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmm}/{external_hmm}_references_for_mapping_NT.fa"),
        headers = os.path.join(dirs_dict['MSA'], "MSA/{external_hmm}/{external_hmm}_headers.tmp")
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
        shell("grep '>' {input.reps} | sed 's/>//g' > {output.headers}")
        shell("anvi-script-reformat-fasta {input.fasta} -I {output.headers} -o {output.NT_for_mapping}")


rule make_fasta_txt:
    """Output fasta.txt that will be used with the metagenomics workflow"""

    version: 1.0
    input:
        expand(os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmms}/{external_hmms}_external_gene_calls_subset.tsv"), external_hmms = M.external_HMM_dict.keys()),
        expand(os.path.join(dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], "{external_hmms}/{external_hmms}_references_for_mapping_NT.fa"), external_hmms = M.external_HMM_dict.keys()),
    output:
        fasta_txt = os.path.join("ECO_PHYLO_WORKFLOW", "fasta.txt"),
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
        fastas = [os.path.join("..", dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], r + "/" + r + '_references_for_mapping_NT.fa') for r in M.external_HMM_dict.keys()]
        external_gene_calls = [os.path.join("..", dirs_dict['RIBOSOMAL_PROTEIN_FASTAS'], r + "/" + r + '_external_gene_calls_subset.tsv') for r in M.external_HMM_dict.keys()]

        list_of_strings = ['\t'.join(t) + '\n' for t in zip(M.external_HMM_dict.keys(), fastas, external_gene_calls)]

        shell('echo -e "name\tpath\texternal_gene_calls" > {output.fasta_txt}')
        shell('echo -n "%s" >> {output.fasta_txt}' % ''.join(list_of_strings))


rule make_metagenomics_config_file:
    """Make a metagenomics_config.json customized for ECO_PHYLO_WORKFLOW"""

    version: 1.0
    input:
        rules.make_fasta_txt.output.fasta_txt
    output:
        config = os.path.join("METAGENOMICS_WORKFLOW", "metagenomics_config.json")
    threads: M.T('anvi_get_external_gene_calls_file')
    run:

        shell('anvi-run-workflow -w metagenomics --get-default-config {output.config}')

        config = open(output.config)
        config_dict = json.load(config)
        config_dict['fasta_txt'] = '../ECO_PHYLO_WORKFLOW/fasta.txt'
        config_dict['samples_txt'] = '../samples.txt'
        config_dict['references_mode'] = True
        config_dict['anvi_run_hmms']['run'] = False
        config_dict["anvi_script_reformat_fasta"]['run'] = False
        config_dict['anvi_run_kegg_kofams']['run'] = False
        config_dict['anvi_run_ncbi_cogs']['run'] = False
        config_dict['anvi_run_scg_taxonomy']['run'] = False
        config_dict['anvi_run_trna_scan']['run'] = False
        config_dict['anvi_run_scg_taxonomy']['run'] = False
        config_dict['iu_filter_quality_minoche']['run'] = False
        config_dict['anvi_profile']['--min-contig-length'] = 0
        config_dict['bowtie']['threads'] = 5

        if M.clusterize_metagenomics_workflow == True:
            config_dict['bowtie']['threads'] = 10
            config_dict['anvi_profile']['threads'] = 10
            config_dict['anvi_merge']['threads'] = 10
        else:
            pass

        with open(output.config, "w") as outfile:
          json.dump(config_dict, outfile, indent=4)


rule run_metagenomics_workflow:
    """Run metagenomics workflow"""

    version: 1.0
    input:
        config = rules.make_metagenomics_config_file.output.config,
    output:
        touch(os.path.join("METAGENOMICS_WORKFLOW", "metagenomics_workflow.done"))
    params:
        HPC_string = M.metagenomics_workflow_HPC_string
    threads: M.T('run_metagenomics_workflow')
    run:
        if M.clusterize_metagenomics_workflow == True:
            shell('cd METAGENOMICS_WORKFLOW/ && anvi-run-workflow -w metagenomics -c metagenomics_config.json --additional-params --cluster \'clusterize -j={{rule}} -o={{log}} -n={{threads}} -x\' --cores 200 --resource nodes=200 --latency-wait 100 --keep-going --rerun-incomplete && cd ..')
        elif M.metagenomics_workflow_HPC_string:
            HPC_string = params.HPC_string
            shell(f'cd METAGENOMICS_WORKFLOW/ && anvi-run-workflow -w metagenomics -c metagenomics_config.json --additional-params --cluster "{HPC_string}" --cores 201 --resource nodes=200 --latency-wait 100 --keep-going --rerun-incomplete && cd ..')
        else:
            shell('cd METAGENOMICS_WORKFLOW/ && anvi-run-workflow -w metagenomics -c metagenomics_config.json -A --rerun-incomplete --latency-wait 100 --keep-going && cd ..')


rule make_anvio_state_file:
    """Make a state file customized for ribo_phylo workflow interactive interface"""

    version: 1.0
    input:
        num_tree_tips = rules.subset_DNA_reps_with_QCd_AA_reps_for_mapping.output.NT_for_mapping,
        done = os.path.join("METAGENOMICS_WORKFLOW/07_SUMMARY", "{external_hmm}_summarize.done")
    output:
        state_file = os.path.join("ECO_PHYLO_WORKFLOW", "{external_hmm}_ECO_PHYLO_WORKFLOW_state.json")
    threads: M.T('anvi_get_external_gene_calls_file')
    run:
        state_dict = {}

        # basics
        state_dict['version'] = '3'
        state_dict['tree-type'] = 'phylogram'

        # height and width
        num_tree_tips = pd.read_csv(input.num_tree_tips, \
                                    sep="\t", \
                                    index_col=None)

        num_SCGs = num_tree_tips.shape[0]
        num_metagenomes = len(M.input_dirs_dict)

        X = 1
        Y = 20
        if num_SCGs < 50:
            state_dict['tree-height'] = '0'
            state_dict['tree-width'] = '0'
        else:
            state_dict['tree-height'] = X * num_SCGs
            state_dict['tree-width'] = Y * num_SCGs

        # layer-orders
        first_layers = ["__parent__", "length", "gc_content"]
        metagenomes = []

        for metagenome in M.input_dirs_dict:
          metagenomes.append(metagenome)

        last_layers = ['split_name', 'percent_identity', 'contig_db_type', 'has_genomic_reference_protein_in_cluster', 'cluster_size', 't_domain', 't_phylum', 't_class', 't_order', 't_family', 't_genus', 't_species']

        layer_order = first_layers + metagenomes + last_layers

        state_dict['layer-order'] = layer_order

        # layers
        layers_dict = {}

        metagenome_layers_dict = {}

        metagenome_attributes = {
          "color": "#000000",
          "height": "180",
          "margin": "15",
          "type": "bar",
          "color-start": "#FFFFFF"
        }

        for metagenome in metagenomes:
            metagenome_layers_dict[str(metagenome)] = metagenome_attributes

        last_layers_dict = {}

        layer_attributes = {
          "color": "#000000",
          "height": "180",
          "margin": "15",
          "type": "color",
          "color-start": "#FFFFFF"
        }

        for layer in last_layers:
            last_layers_dict[str(layer)] = layer_attributes

        layer_attributes_parent = {
          "color": "#000000",
          "height": "0",
          "margin": "15",
          "type": "color",
          "color-start": "#FFFFFF"
        }

        layers_dict.update(metagenome_layers_dict)
        layers_dict.update(last_layers_dict)
        layers_dict['__parent__'] = layer_attributes_parent

        state_dict['layers'] = layers_dict

        with open(output.state_file, "w") as outfile:
                  json.dump(state_dict, outfile, indent=4)

if M.run_iqtree == True:
  rule calculate_tree:
      """Calculate a phylogenetic tree using iqtree"""

      version: 1.0
      log: os.path.join(dirs_dict['LOGS_DIR'], "iqtree_{external_hmm}.log")
      input: rules.remove_sequences_with_X_percent_gaps.output
      output: 
          tree = os.path.join(dirs_dict['TREES'], "{external_hmm}/{external_hmm}.iqtree"),
          done = touch(os.path.join(dirs_dict['TREES'], "{external_hmm}/{external_hmm}_tree.done"))
      params:
          outfile=os.path.join(dirs_dict['TREES'], "{external_hmm}/{external_hmm}"),
          model = M.get_param_value_from_config(['iqtree', '-m']),
          additional_params = M.get_param_value_from_config(['iqtree', 'additional_params'])
      threads: M.T('iqtree')
      shell:
          "iqtree -s {input} \
                  -nt AUTO \
                  -m {params.model} \
                  -pre {params.outfile} \
                  -T AUTO \
                  {params.additional_params} >> {log} 2>&1"

elif M.run_fasttree == True:
  rule calculate_tree:
      """Want to go faster?? Then Fasttree"""

      version: 1.0
      log: os.path.join(dirs_dict['LOGS_DIR'], "fasttree_{external_hmm}.log")
      input: rules.remove_sequences_with_X_percent_gaps.output
      output:
          tree = os.path.join(dirs_dict['TREES'], "{external_hmm}/{external_hmm}.nwk"),
          done = touch(os.path.join(dirs_dict['TREES'], "{external_hmm}/{external_hmm}_tree.done"))
      params:
          additional_params = M.get_param_value_from_config(['fasttree', 'additional_params'])
      threads: M.T('fasttree')
      shell:
          "FastTree -fastest {input} 2> {log} 1> {output.tree}"

rule add_default_collection:
    """"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "add_default_collection_{external_hmm}.log")
    input: metagenomics_workflow_done = os.path.join("METAGENOMICS_WORKFLOW", "metagenomics_workflow.done")
    params:
        contigsDB = ancient(os.path.join("METAGENOMICS_WORKFLOW/03_CONTIGS", "{external_hmm}-contigs.db")),
        profileDB = os.path.join("METAGENOMICS_WORKFLOW/06_MERGED", "{external_hmm}", "PROFILE.db")
    output: touch(os.path.join("METAGENOMICS_WORKFLOW", "{external_hmm}_add_default_collection.done"))
    threads: 2
    shell:
        """
        anvi-script-add-default-collection -c {params.contigsDB} \
                                           -p {params.profileDB}
        """

rule anvi_summarize:
    """
    """

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_summarize_{external_hmm}.log")
    input: 
        done = os.path.join("METAGENOMICS_WORKFLOW", "{external_hmm}_add_default_collection.done")
    params:
        contigsDB = ancient(os.path.join("METAGENOMICS_WORKFLOW/03_CONTIGS", "{external_hmm}-contigs.db")),
        profileDB = os.path.join("METAGENOMICS_WORKFLOW/06_MERGED", "{external_hmm}", "PROFILE.db"),
        output_dir = os.path.join("METAGENOMICS_WORKFLOW/07_SUMMARY", "{external_hmm}")
    output: touch(os.path.join("METAGENOMICS_WORKFLOW/07_SUMMARY", "{external_hmm}_summarize.done"))
    threads: 2
    shell:
        """
        anvi-summarize -c {params.contigsDB} \
                       -p {params.profileDB} \
                       -o {params.output_dir} \
                       -C DEFAULT \
                       --init-gene-coverages \
                       --just-do-it;

        """


rule rename_tree_tips:
    """Joins read recruitment and taxonomy data for interactive interface"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "combine_data_{external_hmm}.log")
    input:
        done = os.path.join("METAGENOMICS_WORKFLOW/07_SUMMARY", "{external_hmm}_summarize.done"),
        tree = rules.calculate_tree.output.tree
    output:
        done = os.path.join("{external_hmm}_combined.done"),
        tree = os.path.join(dirs_dict['TREES'], "{external_hmm}/{external_hmm}_renamed.nwk")
    threads: 2
    run:
        from ete3 import Tree

        t = Tree(input.tree)

        for leaf in t:
            leaf.name = leaf.name + "_split_00001"

        t.write(format = 1, outfile = output.tree)

        shell('touch {output}')


rule anvi_import_state:
    """Import state file for interactive interface"""

    version: 1.0
    log: os.path.join(dirs_dict['LOGS_DIR'], "anvi_import_state_{external_hmm}.log")
    input:
        rules.make_anvio_state_file.output
    params:
        state_file = os.path.join("ECO_PHYLO_WORKFLOW", "{external_hmm}_ECO_PHYLO_WORKFLOW_state.json"),
        profileDB = os.path.join("METAGENOMICS_WORKFLOW/06_MERGED", "{external_hmm}", "PROFILE.db")
    output: touch(os.path.join("{external_hmm}_state_imported.done"))
    threads: 2
    shell:
        """
        anvi-import-state -p {params.profileDB} \
                          -s {params.state_file} \
                          -n {wildcards.external_hmm}
        """
