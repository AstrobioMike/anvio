#!/usr/bin/env python
# -*- coding: utf-8

"""
Copyright (C) 2014, PaPi Authors

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 2 of the License, or (at your option)
any later version.

Please read the COPYING file.
"""

import os
import sys
import pysam
import hashlib
import subprocess
import PaPi.db
import PaPi.genes
import PaPi.contig
import PaPi.fastalib as u
import PaPi.utils as utils
import PaPi.dictio as dictio
import PaPi.terminal as terminal
import PaPi.constants as constants
import PaPi.clustering as clustering
import PaPi.filesnpaths as filesnpaths

from PaPi.clusteringconfuguration import ClusteringConfiguration
from PaPi.metadata import gen_tnf_tables
from PaPi.profiler import __version__

pp = terminal.pretty_print
kmers = PaPi.kmers.KMers()
P = lambda x, y: os.path.join(x['output_dir'], y)


class MultipleRuns:
    def __init__(self, args):
        self.progress = terminal.Progress()
        self.run = terminal.Run()

        self.sample_id = args.sample_id
        self.merged_sample_ids = []
        self.merged_sample_runinfos = {}
        self.merged_sample_runinfo_dict_paths = args.input
        self.contigs = {}
        self.split_names = None
        self.normalization_multiplier = {}
        self.profiles = []
        self.output_directory = args.output_dir

        self.profile_db = None
        self.profile_db_path = None

        self.clustering_configs = constants.clustering_configs['merged']


    def read_runinfo_dict(self, path):
        runinfo = dictio.read_serialized_object(path)
        sample_id = runinfo['sample_id']
        if not sample_id in self.merged_sample_ids:
            self.merged_sample_ids.append(sample_id)
        self.merged_sample_runinfos[sample_id] = runinfo
        return sample_id, runinfo


    def read_runinfo_dicts(self):
        improper = []
        missing_path = []
        bad_profiler_version = []

        for p in self.merged_sample_runinfo_dict_paths:
            sample_id, runinfo = self.read_runinfo_dict(p)
            try:
                sample_id, runinfo = self.read_runinfo_dict(p)
            except:
                improper.append(p)
                continue

            # if things are not where they should be, we attempt to reset the directory paths.
            if not os.path.exists(P(runinfo, runinfo['profile_db'])):
                new_output_dir = os.path.dirname(os.path.join(os.getcwd(), p))
                old_output_dir = runinfo['output_dir']

                runinfo = dictio.reset_output_dir(p, old_output_dir, new_output_dir)

                # if the paths are still f'd up, store it as bad.
                if not os.path.exists(P(runinfo, runinfo['profile_db'])):
                    missing_path.append(p)

            if not runinfo.has_key('profiler_version') or runinfo['profiler_version'] != PaPi.profiler.__version__:
                bad_profiler_version.append(p)

        if improper:
            raise utils.ConfigError, "%s seem to be properly formatted PaPi object: %s. Are you\
                                           sure these are PaPi RUNINFO.cp files?" % \
                                           ('Some RUNINFO files do not' if len(improper) > 1 else "RUNINFO file does not",
                                            ', '.join(improper))

        if missing_path:
            raise utils.ConfigError, "%d of %d files you provided have bad file paths: %s. PaPi tried to fix them, but\
                                           it failed. Maybe these RUNINFO.cp files were generated on another\
                                           machine? Or maybe they were edited manually? Well, PaPi is as lost as you\
                                           are at this point :(" % (len(missing_path),
                                                                    len(self.merged_sample_runinfos),
                                                                    ', '.join(['"%s"' % x for x in missing_path]))

        if bad_profiler_version:
            raise utils.ConfigError, "%d of %d RUNINFO.cp files you provided seems to be generated by an\
                                           older version of PaPi profiler that is not compatible with the current\
                                           merger anymore. You need to re-run PaPi profiler on these projects: %s" \
                                                        % (len(bad_profiler_version),
                                                           len(self.merged_sample_runinfos),
                                                           ', '.join(['"%s"' % x for x in bad_profiler_version]))


    def sanity_check(self):
        if not self.output_directory:
            raise utils.ConfigError, "Sorry. You must declare an output directory path."

        self.output_directory = os.path.abspath(self.output_directory)

        if os.path.exists(self.output_directory):
            raise utils.ConfigError, "The output directory you asked for exists. PaPi does not like overwriting stuff."

        if not len(self.merged_sample_runinfo_dict_paths) > 1:
            raise utils.ConfigError, "You need to provide at least 2 RUNINFO.cp files for this program\
                                           to be useful."

        missing = [p for p in self.merged_sample_runinfo_dict_paths if not os.path.exists(p)]
        if missing:
            raise utils.ConfigError, "%s not found: %s." % ('Some files are' if len(missing) > 1 else "File is",
                                                                 ', '.join(missing))

        self.read_runinfo_dicts()

        if [True for v in self.merged_sample_runinfos.values() if v['merged']]:
            raise utils.ConfigError, "This is very cute, but you can't merge already merged runs. PaPi can only merge\
                                      individual profiles (which are generated through papi-profile program). Sorry."

        for k, p in [('split_length', 'Split length (-L)'),
                     ('min_contig_length', 'Minimum contig length (-M)'),
                     ('min_mean_coverage', 'Minimum mean coverage (-C)')]:
            v = set([r[k] for r in self.merged_sample_runinfos.values()])
            if len(v) > 1:
                raise utils.ConfigError, "%s is not identical for all runs to be merged, which is a \
                                          deal breaker. You need to profile all runs to be merged with\
                                          identical parameters :/" % p

            # so we carry over this information into the runinfo dict for merged runs:
            self.run.info(k, v.pop())

        # make sure all the split names are identical across runs
        sample_runinfos = self.merged_sample_runinfos.values()
        self.split_names = set(self.get_split_names(sample_runinfos[0]))
        for sample_runinfo in sample_runinfos[1:]:
            if self.split_names != set(self.get_split_names(sample_runinfo)):
                raise utils.ConfigError, "All runs to be merged must contain identical split names (which would be the\
                                          case if they are samples mapped to the same contigs). But it does not seem\
                                          to be the case here. At least one run (namely, '%s') differs from a randomly\
                                          chosen another one (namely, '%s'). PaPi hopes that you know how to fix this\
                                          :/"% (sample_runinfos[0]['sample_id'], sample_runinfo['sample_id'])
        self.split_names = sorted(list(self.split_names))

        # make sure all runs were profiled using the same annotation database (if one used):
        annotation_hashes = set([r['annotation_hash'] for r in sample_runinfos])
        if len(annotation_hashes) != 1:
            if None in annotation_hashes:
                raise utils.ConfigError, "It seems there is at least one run in the mix that was profiled using an\
                                          annotation database, and at least one other that was profiled without using\
                                          one. This is not good. All runs must be profiled using the same annotation\
                                          database, or all runs must be profiled without an annotation database :/"
            else:
                raise utils.ConfigError, "It seems these runs were profiled using different annotation databases (or\
                                          different versions of the same annotation database). All runs must be\
                                          profiled using the same annotation database, or all runs must be profiled\
                                          without an annotation database :/"


    def set_sample_id(self):
        if self.sample_id:
            utils.check_sample_id(self.sample_id)
        else:
            self.sample_id = os.path.basename(self.output_directory)
            self.sample_id = self.sample_id.replace('-', '_')
            if self.sample_id[0] in constants.digits:
                self.sample_id = 's' + self.sample_id
            utils.check_sample_id(self.sample_id)


    def merge_genes_tables(self):
        gene_tables_present = [runinfo['genes_table'] for runinfo in self.merged_sample_runinfos.values()]

        if gene_tables_present.count(True) == len(self.merged_sample_runinfos.values()):
            self.run.info('genes_table', True, quiet = True)
        elif gene_tables_present.count(False) == len(self.merged_sample_runinfos.values()):
            # none has it
            self.run.info('genes_table', False, quiet = True)
            return
        else:
            # some weird shit must have happened.
            raise utils.ConfigError, "PaPi is confused. While merging multiple runs, it seem some of the runs have the\
                                      'genes' table in their PROFILE.db's, and others do not. This is so weird, and it\
                                      does not make any sense. Probably you should profile everything from scratch just\
                                      to be on the safe side :/"

        # create an instance from genes
        genes = PaPi.genes.Genes()

        # fill "genes" instance from all samples
        for runinfo in self.merged_sample_runinfos.values():
            sample_id = runinfo['sample_id']
            sample_profile_db_path = P(runinfo, runinfo['profile_db'])
            sample_profile_db = PaPi.db.DB(sample_profile_db_path, __version__)
            sample_gene_profiles = sample_profile_db.get_table_as_dict('genes', PaPi.genes.genes_table_structure)
            for g in sample_gene_profiles.values():
                genes.add_gene_entry(g['prot'], g['sample_id'], g['mean_coverage'] * self.normalization_multiplier[sample_id])

        genes.create_genes_table(self.profile_db)


    def set_normalization_multiplier(self):
        # WARNING: here we normalize gene coverages based on total number of reads mapped per sample.
        # this is not the best way to do it. a better way probably required all reads obtained from each
        # run, yet even that would wrongly assume equal eukaryotic contamination, etc. normalization is a bitch.
        num_reads_mapped_per_sample = {}
        for runinfo in self.merged_sample_runinfos.values():
            sample_profile_db_path = P(runinfo, runinfo['profile_db'])
            sample_profile_db = PaPi.db.DB(sample_profile_db_path, __version__)
            num_reads_mapped_per_sample[runinfo['sample_id']] = int(sample_profile_db.get_meta_value('total_reads_mapped'))

        smallest_sample_size = min(num_reads_mapped_per_sample.values())

        for sample_id in num_reads_mapped_per_sample:
            self.normalization_multiplier[sample_id] = smallest_sample_size * 1.0 / num_reads_mapped_per_sample[sample_id] 

        PRETTY = lambda x: ', '.join(['%s: %.2f' % (s, x[s]) for s in x])
        self.run.info('WARNING', utils.remove_spaces("PaPi just set the normalization values for each sample based on\
                                                      how many mapped reads they contained. All normalized coverages\
                                                      will use this information: %s" % PRETTY(self.normalization_multiplier)),
                                                      display_only = True, header = True)


    def merge(self):
        self.sanity_check()
        self.set_sample_id()

        filesnpaths.gen_output_directory(self.output_directory)

        # init profile database
        self.profile_db_path = os.path.join(self.output_directory, 'PROFILE.db')
        self.profile_db = PaPi.db.DB(self.profile_db_path, __version__, new_database = True)
        # put sample id into the meta table
        self.profile_db.set_meta_value('sample_id', self.sample_id)
        self.profile_db.set_meta_value('merged', True)
        annotation_hash = self.merged_sample_runinfos.values()[0]['annotation_hash']
        self.profile_db.set_meta_value('annotation_hash', annotation_hash)
        self.run.info('annotation_hash', annotation_hash)

        # get metadata information for both contigs and splits:
        self.metadata_fields, self.metadata_for_each_run = self.read_metadata_tables()
        self.split_parents = self.get_split_parents()

        self.progress.new('Reading contigs into memory')
        self.read_contigs()
        self.progress.end()

        self.run.info('profiler_version', __version__)
        self.run.info('output_dir', self.output_directory)
        self.run.info('sample_id', self.sample_id)
        self.run.info('profile_db', self.profile_db_path)
        self.run.info('merged', True)
        self.run.info('merged_sample_ids', self.merged_sample_ids)
        self.run.info('cmd_line', utils.get_cmd_line())
        self.run.info('num_runs_processed', len(self.contigs))
        self.run.info('num_splits_found', pp(len(self.contigs.values()[0])))
        self.run.info('contigs_total_length', pp(sum([len(s) for s in self.contigs.values()[0]])))
 
        self.set_normalization_multiplier()
 
        self.progress.new('Merging genes tables')
        self.merge_genes_tables()
        self.progress.end()
 
        self.progress.new('Generating merged summary')
        summary_dir, profile_summary_index = self.merge_split_summaries()
        self.progress.end()
        self.run.info('profile_summary_dir', summary_dir)
        self.run.info('profile_summary_index', profile_summary_index)

        self.progress.new('Analyzing contigs for consensus')
        splits_fasta = self.store_splits_consensus()
        self.progress.end()
        self.run.info('splits_fasta', splits_fasta)

        self.progress.new('GC content for consensus splits')
        self.progress.update('Computing...')
        self.GC_content_for_splits = utils.get_GC_content_for_FASTA_entries(splits_fasta)
        self.progress.end()

        self.progress.new('Analyzing TNF of contigs')
        self.store_tnf_for_contigs_and_splits()
        self.progress.end()

        # critical part:
        self.merge_metadata_files()
        self.cluster_contigs()

        self.progress.end()


        runinfo_serialized = os.path.join(self.output_directory, 'RUNINFO.mcp')
        self.run.info('runinfo', runinfo_serialized)
        self.run.store_info_dict(runinfo_serialized, strip_prefix = self.output_directory)

        self.run.quit()
        self.profile_db.disconnect()


    def merge_metadata_files(self):
        essential_fields = [f for f in self.metadata_fields if constants.IS_ESSENTIAL_FIELD(f)]
        auxiliary_fields = [f for f in self.metadata_fields if constants.IS_AUXILIARY_FIELD(f)]
        # FIXME: these are pretty embarrassing, and should be fixed at some point:
        Length = "length"
        GC_content = "GC_content"

        views = {}

        # get split lenghs from one of the metadata files for fast access:
        m = self.metadata_for_each_run['splits'].values()[0]
        self.contig_lengths = dict([(split_name, m[split_name]['length']) for split_name in m])

        # setting standard metadata table structure and types
        merged_mtable_structure = ['contig', 'length', 'GC_content'] + self.merged_sample_ids + auxiliary_fields
        merged_mtable_types = ['text'] + ['numeric'] * (len(self.merged_sample_ids) + 2) + ['text']


        self.progress.new('Generating metadata tables')
        for target in ['contigs', 'splits']:
            for essential_field in essential_fields:
                self.progress.update('Processing %s for %s ...' % (essential_field, target))

                target_table = '_'.join([essential_field, target])

                m = {}
                for split_name in self.split_names:
                    m[split_name] = {'GC_content': self.GC_content_for_splits[split_name],
                                     'length': self.contig_lengths[split_name],
                                     '__parent__': self.split_parents[split_name]}
                    for sample_id in self.merged_sample_ids:
                        if essential_field == 'noramlized_coverage':
                            # and here my programming career hits a new bottom with the following line. I will fix all this
                            # shit very soon; that is how I contain my rage towards myself.
                            m[split_name][sample_id] = self.metadata_for_each_run[target][sample_id][split_name][essential_field] * self.normalization_multiplier[sample_id]
                        else:
                            m[split_name][sample_id] = self.metadata_for_each_run[target][sample_id][split_name][essential_field]

                self.profile_db.create_table(target_table, merged_mtable_structure, merged_mtable_types)
                db_entries = [tuple([split_name] + [m[split_name][h] for h in merged_mtable_structure[1:]]) for split_name in self.split_names]
                self.profile_db._exec_many('''INSERT INTO %s VALUES (%s)''' % (target_table, ','.join(['?'] * len(merged_mtable_structure))), db_entries)

                if target == 'splits':
                    views[essential_field] = target_table

        self.profile_db.commit()
        self.progress.end()
        # fill the runinfo dict with visualization targets:
        self.run.info('views', views, quiet = True)
        # this is not very flexible:
        self.run.info('default_view', 'mean_coverage', quiet = True)


    def cluster_contigs(self):
        # clustering of contigs is done for each configuration file under static/clusterconfigs/merged directory;
        # at this point we don't care what those recipes really require because we already merged and generated
        # every metadata file that may be required.
        clusterings = {}
        for config_name in self.clustering_configs:
            config_path = self.clustering_configs[config_name]
            config = ClusteringConfiguration(config_path, self.output_directory, version = __version__)
            newick_path = clustering.order_contigs_simple(config, progress = self.progress)
            clusterings[config_name] = os.path.basename(newick_path)
        self.run.info('clusterings', clusterings)
        self.run.info('default_clustering', constants.merged_default)


    def merge_split_summaries(self):
        merged_summary_index = {}
        merged_summary_index_path = os.path.join(self.output_directory, 'SUMMARY.cp')
        summary_dir = filesnpaths.gen_output_directory(os.path.join(self.output_directory, 'SUMMARY'), delete_if_exits = True)

        
        # read all index files per run into a dict here, so the access is easier from within
        # the for loop below
        run_sum_indices = {}
        for runinfo  in self.merged_sample_runinfos.values():
            r = P(runinfo, runinfo['profile_summary_index'])
            run_sum_indices[runinfo['sample_id']] = dictio.read_serialized_object(r)

        for i in range(0, len(self.split_names)):
            self.progress.update('merging summaries for splits %s of %s' % (i + 1, len(self.split_names)))
            split_name = self.split_names[i]

            merged_summary = {}
            for runinfo in self.merged_sample_runinfos.values():
                r = P(runinfo, run_sum_indices[runinfo['sample_id']][split_name])
                run_split_summary = dictio.read_serialized_object(r)
                merged_summary[runinfo['sample_id']] = run_split_summary[runinfo['sample_id']]

            merged_split_summary_path = os.path.join(summary_dir, os.path.basename(run_sum_indices[runinfo['sample_id']][split_name]))
            dictio.write_serialized_object(merged_summary, merged_split_summary_path)
            merged_summary_index[split_name] = merged_split_summary_path

        self.progress.update('Serializing merged split summary index ...')
        dictio.write_serialized_object(dictio.strip_prefix_from_dict_values(merged_summary_index, self.output_directory),\
                                           merged_summary_index_path)

        return summary_dir, merged_summary_index_path


    def get_split_parents(self):
        parents = {}
        m = self.metadata_for_each_run['splits'].values()[0]
        for split in m:
            parents[split] = m[split]["__parent__"]
        return parents


    def read_metadata_tables(self):
        """reads metadata files of contigs and splits into a dict"""
        metadata_for_each_run = {}

        for target in ['contigs', 'splits']:
            metadata_for_each_run[target] = {}

            target_table = 'metadata_%s' % target

            for r in self.merged_sample_runinfos.values():
                db = PaPi.db.DB(os.path.join(r['output_dir'], r['profile_db']), __version__)
                metadata_for_each_run[target][r['sample_id']] = db.get_table_as_dict(target_table)

        metadata_fields = db.get_table_structure('metadata_splits')
        db.disconnect()

        return metadata_fields, metadata_for_each_run


    def get_split_names(self, sample_runinfo):
        db = PaPi.db.DB(os.path.join(sample_runinfo['output_dir'], sample_runinfo['profile_db']), __version__)
        split_names = db.get_single_column_from_table('metadata_splits', 'contig')
        db.disconnect()
        return split_names


    def read_contigs(self):
        for i in range(0, len(self.merged_sample_ids)):
            self.progress.update('%d of %d' % (i + 1, len(self.merged_sample_ids)))
            sample_id = self.merged_sample_ids[i]
            runinfo = self.merged_sample_runinfos[sample_id]
            fasta = u.SequenceSource(P(runinfo, runinfo['splits_fasta']))
            contigs = {}
            while fasta.next():
                contigs[fasta.id] = fasta.seq
            self.contigs[sample_id] = contigs


    def store_tnf_for_contigs_and_splits(self):
        # what we call a contig, is actually a split. we can't run TNF analysis on a split; instead,
        # we analyze TNF on the parent contig where each split is coming form. it is handled very
        # clearly in papi-profiler, but unfortunately I have been doing some pretty horrible coding
        # here for no reason. so, we already identified which split is associated with what parent
        # contig at this point. now we will generate a parents dict where we will keep properly
        # merged split seqs and their TNF. because we will concatenate split seqs the way they are
        # ordered, it is critical for metadata file to be sorted properly (a later split in order
        # should not appear in the METADATA file earlier). OK. First, lets put sequences in:
        num_splits = len(self.split_names)
        parents_dict = {}
        for i in range(0, num_splits):
            if (i + 1) % 10 == 0 or (i + 1) == num_splits:
                self.progress.update('Generating merged split consensus sequences :: %.2f%%' % ((i + 1) * 100.0/ num_splits))

            split_name = self.split_names[i]
            parent = self.split_parents[split_name]
            
            if parents_dict.has_key(parent):
                parents_dict[parent]['seq'] += self.consensus_splits[split_name]
            else:
                parents_dict[parent] = {'seq': self.consensus_splits[split_name]}

        # ok. now parents_dict contains all the sequences. lets get TNF info:
        parents = parents_dict.keys()
        num_parents = len(parents)
        for i in range(0, num_parents):
            self.progress.update('Computing TNF for merged splits :: %.2f%%' % ((i + 1) * 100.0/ num_parents))

            parent = parents[i]
            parents_dict[parent]['tnf'] = kmers.get_kmer_frequency(parents_dict[parent]['seq'])

        # nice. parents_dict looks like this:
        #
        # {
        #    'contig_1': {'seq': 'ATCATCATC(...)', 'tnf':{'AAAA': 100, 'AAAC': 100, (...)}},
        #    'contig_2': {'seq': 'GATGATGAT(...)', 'tnf':{'AAAA': 100, 'AAAC': 100, (...)}},
        #    (...)
        # }
        #

        self.progress.update('Populating TNF variables ...')
        tnf_splits = {}
        tnf_contigs = {}

        keys = kmers.kmers.values()[0]

        for parent in set(self.split_parents.values()):
            tnf_contigs[parent] = parents_dict[parent]['tnf']

        for split_name in self.split_names:
            tnf_splits[split_name] = kmers.get_kmer_frequency(self.consensus_splits[split_name])
            tnf_splits[split_name]['__parent__'] = self.split_parents[split_name]

        self.progress.update('Creating TNF tables ...')
        gen_tnf_tables(sorted(list(keys)), tnf_splits, tnf_contigs, self.profile_db)


    def store_splits_consensus(self):
        self.consensus_splits = {}
        num_splits = len(self.split_names)
        for i in range(0, num_splits):
            if (i + 1) % 10 == 0:
                self.progress.update('%.2f%%' % ((i + 1) * 100.0/ num_splits))
            
            split_name = self.split_names[i]

            sequences = set()

            for run in self.contigs:
                sequences.add(self.contigs[run][split_name])
            contig_length = len(self.contigs[run][split_name])

            if len(sequences) == 1:
                # perfect. all consensus sequences recovered by PaPi profiler for each sample is identical
                # this happens only when all reads from all samples were mapped on the contig.
                self.consensus_splits[split_name] = sequences.pop()
            else:
                # this means there are more than one consensus sequences. they are going to be identical,
                # except some of them will have N's because not all samples mapped at all regions of the
                # consensus.
                #
                # (inline FIXME: ^^ this information is critical to retain and visualize.)
                #
                # now these need to be merged into contigs that have no N's.
                #
                new_consensus = ''
                for j in range(0, contig_length):
                    nt_list = [seq[j] for seq in sequences if seq[j] != 'N']
                    if nt_list:
                        new_consensus += nt_list[0]
                    else:
                        new_consensus += 'N'
                self.consensus_splits[split_name] = new_consensus

        self.progress.update('Storing contigs ...')
        output_file_path = os.path.join(self.output_directory, 'CONTIGS-CONSENSUS.fa')
        output = open(output_file_path, 'w')
        for split_name in self.consensus_splits:
            output.write('>%s\n%s\n' % (split_name, self.consensus_splits[split_name]))
        output.close()

        return output_file_path


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Merge multiple PaPi runs to do cross-sectional or timeseries comparisons')
    parser.add_argument('input', metavar = 'RUNINFO_FILE', nargs='+',
                        help = 'PaPi RUNINFO files to create a merged output')
    parser.add_argument('-o', '--output-dir', help = 'Output directory')
    parser.add_argument('-s', '--sample-id', metavar = 'NAME', default = None,
                        help = 'It is important to set a sample name (using only ASCII letters and digits\
                                and without spaces) that is unique to a particular merged run. If you do not\
                                provide one, PaPi will make up one for you based on the output_directory\
                                name you set (although, you should never let the software to decide these\
                                things).')


    args = parser.parse_args()

    try:
        MultipleRuns(args).merge()
    except utils.ConfigError, e:
        print e
        sys.exit(-1)

