#!/usr/bin/env python
# -*- coding: utf-8
"""Entry point to the interactive interface.

The massage of the data is being taken care of in the interactive module,
and this file implements the bottle callbacks."""

import os
import sys
import json
import base64
import shutil
import argparse
import webbrowser
import datetime

from multiprocessing import Process
from bottle import route, static_file, redirect, request, BaseRequest, response
from bottle import run as run_server

import PaPi.utils as utils
import PaPi.dictio as dictio
import PaPi.filesnpaths as filesnpaths
import PaPi.interactive as interactive
import PaPi.terminal as terminal

__author__ = "Özcan Esen"
__copyright__ = "Copyright 2015, The PaPi Project"
__credits__ = ["Gökmen Görgen"]
__license__ = "GPL 3.0"
__version__ = "1.0.0"
__maintainer__ = "A. Murat Eren"
__email__ = "a.murat.eren@gmail.com"
__status__ = "Development"


run = terminal.Run()


# get the absolute path for static directory under PaPi
static_dir = os.path.join(os.path.dirname(utils.__file__), 'data/interactive')

parser = argparse.ArgumentParser(description='Start PaPi binning interface')
# FIXME: it should be possible to run this without the runinfo-dict.
parser.add_argument('-r', '--runinfo', metavar = 'PATH', default = None,
                    help = 'RUNINFO.cp file generated by a PaPi profiler')
parser.add_argument('-v', '--view', metavar = 'VIEW', default = None,
                    help = 'What view to show on the interface. To see a list of available views, use --show-views flag.')
parser.add_argument('-a', '--annotation-db', metavar = 'DB_FILE', default = None,
                    help = 'Annotation database generated by "papi-gen-annotation". Inclusion of\
                            this file will drastically increase the usefulness of the pipeline.')
parser.add_argument('-f', '--fasta-file', metavar = 'FASTA', default = None,
                    help = 'FASTA file of consensus sequences for each split')
parser.add_argument('-m', '--metadata', metavar = 'TXT', default = None,
                    help = 'TAB-delimited metadata file')
parser.add_argument('-t', '--tree', metavar = 'NEWICK', default = None,
                    help = 'Newick tree of contigs. Declaring a tree file using this parameter will override\
                            the tree file in RUNINFO.')
parser.add_argument('--title', metavar = "TITLE", default = None,
                    help = "Title for the interface. If you are working with a RUNINFO dict, the title\
                            will be determined based on information stored in that file. Regardless,\
                            you can override that value using this parameter. If you are not using a\
                            PaPi RUNINFO dictionary, a meaningful title will appear in the interface\
                            only if you define one using this parameter.")
parser.add_argument('-A', '--additional-metadata', metavar = "FILE", default = None,
                    help = "A TAB-delimited file for additional metadata for contigs. The file should\
                            contain all contigs that are present in other files.")
parser.add_argument('-S', '--summary-index', metavar = "FILE", default = None,
                     help = "SUMMARY.cp, if there is one available, to inspect contigs from the interface. Will\
                             override the one found in RUNINFO file if it was also declared using -r parameter.")
parser.add_argument('-o', '--output-dir', metavar = 'DIRECTORY', default = None,
                    help = 'Output directory for output storage')
parser.add_argument('-p', '--port-number', metavar = 'INT', default = 8080, type=int,
                    help = 'Port number to use for communication; the default\
                            (%(default)d) should be OK for almost everyone.')
parser.add_argument('-I', '--ip-address', metavar = 'IO', default = '0.0.0.0', type=str,
                    help = 'IP address for the HTTP server. The default ip address (%(default)s) should\
                            work just fine for most.')
parser.add_argument('-s', '--state', metavar = "FILE", default = None,
                    help = "State file for loading previous session.")
parser.add_argument('--show-views', action = 'store_true', default = False,
                        help = 'When declared, the program will show a list of available views, and exit.')
parser.add_argument('--dry-run', action = 'store_true', default = False,
                        help = 'Do not start the server, do not fire up the browser.')


try:
    d = interactive.InputHandler(parser.parse_args())
except utils.ConfigError, e:
    print e
    sys.exit(-1)
except filesnpaths.FilesNPathsError, e:
    print e
    sys.exit(-1)


#######################################################################################################################
# bottle callbacks start
#######################################################################################################################

@route('/')
def redirect_to_app():
    redirect('/app/index.html')

@route('/app/:filename#.*#')
def send_static(filename):
    response.set_header('Content-Type', 'application/json')
    response.set_header('Pragma', 'no-cache')
    response.set_header('Cache-Control', 'no-cache, no-store, max-age=0, must-revalidate')
    response.set_header('Expires', 'Thu, 01 Dec 1994 16:00:00 GMT')
    return static_file(filename, root=static_dir)

@route('/data/<name>')
def send_data(name):
    response.set_header('Content-Type', 'application/json')
    response.set_header('Pragma', 'no-cache')
    response.set_header('Cache-Control', 'no-cache, no-store, max-age=0, must-revalidate')
    response.set_header('Expires', 'Thu, 01 Dec 1994 16:00:00 GMT')
    if name == "clusterings":
        return json.dumps((d.runinfo['default_clustering'], d.runinfo['clusterings']), )
    elif name == "views":
        available_views = dict(zip(d.runinfo['views'].keys(), d.runinfo['views'].keys()))
        return json.dumps((d.runinfo['default_view'], available_views), )
    elif name == "default_view":
        return json.dumps(d.runinfo['views'][d.runinfo['default_view']])
    elif name == "state":
        if d.state:
            return static_file(os.path.abspath(d.state), root='/')
        return "{}"
    elif name == "contig_lengths":
        return json.dumps(d.contig_lengths)
    elif name == "title":
        return json.dumps(d.title)

@route('/data/view/<view_id>')
def get_view_data(view_id):
    return json.dumps(d.runinfo['views'][view_id])

@route('/tree/<tree_id>')
def send_data(tree_id):
    response.set_header('Content-Type', 'application/json')
    response.set_header('Pragma', 'no-cache')
    response.set_header('Cache-Control', 'no-cache, no-store, max-age=0, must-revalidate')
    response.set_header('Expires', 'Thu, 01 Dec 1994 16:00:00 GMT')

    if tree_id in d.runinfo['clusterings']:
        run.info_single("Clustering of '%s' has been requested" % (tree_id))
        return json.dumps(d.runinfo['clusterings'][tree_id]['newick'])

@route('/data/charts/<contig_name>')
def charts(contig_name):
    data = {'layers': [],
             'index': None,
             'total': None,
             'coverage': [],
             'variability': [],
             'competing_nucleotides': [],
             'previous_contig_name': None,
             'next_contig_name': None,
             'genes': []}

    if not d.contigs_summary_index.has_key(contig_name):
        return data

    index_of_contig = d.contig_names_ordered.index(contig_name)
    if index_of_contig:
        data['previous_contig_name'] = d.contig_names_ordered[index_of_contig - 1]
    if (index_of_contig + 1) < len(d.contig_names_ordered):
        data['next_contig_name'] = d.contig_names_ordered[index_of_contig + 1]

    data['index'] = index_of_contig + 1
    data['total'] = len(d.contig_names_ordered)

    contigs = dictio.read_serialized_object(d.P(d.contigs_summary_index[contig_name]))
    layers = sorted(contigs.keys())

    for layer in layers:
        data['layers'].append(layer)
        data['coverage'].append(contigs[layer]['coverage'])
        data['variability'].append(contigs[layer]['variability'])
        data['competing_nucleotides'].append(contigs[layer]['competing_nucleotides'])

    levels_occupied = {1: []}
    if d.split_to_genes_in_splits_ids.has_key(contig_name):
        for entry_id in d.split_to_genes_in_splits_ids[contig_name]:
            prot_id = d.genes_in_splits[entry_id]['prot']
            p = d.genes_in_splits[entry_id]
            # p looks like this at this point:
            #
            # {'percentage_in_split': 100,
            #  'start_in_split'     : 16049,
            #  'stop_in_split'      : 16633}
            #  'prot'               : u'prot2_03215',
            #  'split'              : u'D23-1contig18_split_00036'}
            #
            # we will add two more attributes:
            p['direction'] = d.genes_in_contigs_dict[prot_id]['direction']
            p['function'] = d.genes_in_contigs_dict[prot_id]['function'] or None

            for level in levels_occupied:
                level_ok = True
                for gene_tuple in levels_occupied[level]:
                    if (p['start_in_split'] >= gene_tuple[0] - 100 and p['start_in_split'] <= gene_tuple[1] + 100) or\
                                (p['stop_in_split'] >= gene_tuple[0] - 100 and p['stop_in_split'] <= gene_tuple[1] + 100):
                        level_ok = False
                        break
                if level_ok:
                    levels_occupied[level].append((p['start_in_split'], p['stop_in_split']), )
                    p['level'] = level
                    break
            if not level_ok:
                levels_occupied[level + 1] = [(p['start_in_split'], p['stop_in_split']), ]
                p['level'] = level + 1

            data['genes'].append(p)

    return json.dumps(data)

@route('/data/contig/<contig_name>')
def contig_info(contig_name):
    return d.contig_rep_seqs[contig_name]

@route('/data/collections')
def collections():
    response.set_header('Content-Type', 'application/json')
    response.set_header('Pragma', 'no-cache')
    response.set_header('Cache-Control', 'no-cache, no-store, max-age=0, must-revalidate')
    response.set_header('Expires', 'Thu, 01 Dec 1994 16:00:00 GMT')

    collections_dict = d.collections.get_collections_dict()

    return json.dumps(collections_dict)

@route('/data/completeness', method='POST')
def completeness():
    completeness_stats = {}
    if not d.completeness:
        return json.dumps(completeness_stats)

    split_names = json.loads(request.forms.get('split_names'))
    group_name = json.loads(request.forms.get('group_name'))

    run.info_single('Completeness info has been requested for %d splits in %s' % (len(split_names), group_name))

    completeness_stats = d.completeness.get_info_for_splits(set(split_names))

    return json.dumps({'stats': completeness_stats, 'refs': d.completeness.http_refs})

@route('/save_state', method='POST')
def save_state():
    state = request.forms.get('state')

    now = datetime.datetime.now()
    state_output_path = os.path.join(d.runinfo['output_dir'], now.strftime("state-%Y-%m-%d-%H-%M-%S.json"))

    state_output = open(state_output_path, 'w')
    state_output.write(state)
    state_output.close()

@route('/submit', method='POST')
def submit():
    bins = json.loads(request.forms.get('groups'))
    svg = request.forms.get('svg')

    if svg:
        # take care of the SVG.
        svg_output_path = os.path.join(d.runinfo['output_dir'], 'BINS.svg')
        print '* Storing SVG data into "%s"' % svg_output_path
        svg_output = open(svg_output_path, 'w')
        svg_output.write(svg)
        svg_output.close()
        d.runinfo['bins_svg'] = svg_output_path

    if not bins:
        return

    # take care of bins.. start by removing the bins dir if it exists.
    bins_dir = os.path.join(d.runinfo['output_dir'], 'BINS')
    if os.path.exists(bins_dir):
        shutil.rmtree(bins_dir)
    os.makedirs(bins_dir)
    print '* Storing bins under "%s"' % bins_dir
    for bin in bins:
        output_path = os.path.join(d.runinfo['output_dir'], 'BINS', bin + '.fa')
        output = open(output_path, 'w')
        for contig in bins[bin]:
            output.write('>%s\n%s\n' % (contig, d.contig_rep_seqs[contig]))
        output.close()

    print

#######################################################################################################################
# bottle callbacks end
#######################################################################################################################

args = parser.parse_args()

port = args.port_number
ip = args.ip_address

port = utils.get_available_port_num(start = port, ip=ip)

if not port:
    run.info_single('PaPi failed to find a port number that is available :(', mc='red')
    sys.exit(-1)

# increase maximum size of form data to 100 MB
BaseRequest.MEMFILE_MAX = 1024 * 1024 * 100 

if args.dry_run:
    run.info_single('Dry run, eh? Bye!', 'red', nl_before = 1, nl_after=1)
    sys.exit()

try:
    server_process = Process(target=run_server, kwargs={'host': ip, 'port': port, 'quiet': True})
    server_process.start()
    webbrowser.open_new("http://%s:%d" % (ip, port))
    run.info_single('When you are finished, press CTRL+C to terminate the server.', 'green', nl_before = 1, nl_after=1)
    server_process.join()
except KeyboardInterrupt:
    run.warning('The server is being terminated.', header='Please wait...')
    server_process.terminate()
    sys.exit(1)
